{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"useful layers This repository is a collection of experimental layer implementations, which might be handy. Warning Please consider that this package is still under active development. Installation The installation should be done using pip. Currently we have not released the first version, so simply install the latest version via github: pip install useful-layers","title":"Home"},{"location":"#useful-layers","text":"This repository is a collection of experimental layer implementations, which might be handy. Warning Please consider that this package is still under active development.","title":"useful layers"},{"location":"#installation","text":"The installation should be done using pip. Currently we have not released the first version, so simply install the latest version via github: pip install useful-layers","title":"Installation"},{"location":"Extending/","text":"useful_layers Extensions Extending the useful_layers packet with own layers is straightforward: Adding Layers To add a new layer implementation simply inherit from useful_layers.Layer . Implement the forward(x: torch.Tensor) -> torch.Tensor: function just as you would do with vanilla pytorch. Adding Blocks To add a new block your implementation has to inherit from useful_layers.Block . Implement the forward(x: torch.Tensor) -> torch.Tensor: function just as you would do with vanilla pytorch.","title":"Extending useful_layers"},{"location":"Extending/#useful_layers-extensions","text":"Extending the useful_layers packet with own layers is straightforward:","title":"useful_layers Extensions"},{"location":"Extending/#adding-layers","text":"To add a new layer implementation simply inherit from useful_layers.Layer . Implement the forward(x: torch.Tensor) -> torch.Tensor: function just as you would do with vanilla pytorch.","title":"Adding Layers"},{"location":"Extending/#adding-blocks","text":"To add a new block your implementation has to inherit from useful_layers.Block . Implement the forward(x: torch.Tensor) -> torch.Tensor: function just as you would do with vanilla pytorch.","title":"Adding Blocks"},{"location":"blocks/Blocks/","text":"useful_layers Blocks module Unlike layers, blocks apply the calculated results directly to the input. A block consists of one or more layers, whose activation map is fused with the original input.","title":"Block Introduction"},{"location":"blocks/Blocks/#useful_layers-blocks-module","text":"Unlike layers, blocks apply the calculated results directly to the input. A block consists of one or more layers, whose activation map is fused with the original input.","title":"useful_layers Blocks module"},{"location":"blocks/ScalingBlock/ScalingBlock/","text":"Scaling Block This block scales (i.e. multiplies) the original input with the activation map. Class - ScalingBlock Simple scaling block. Parameter type Description input_layer useful_layers.layer Layer implementation to calculate activation map Return Value The returned value is the product of the original input and the output of the layer. Example A simple usage example without context: import torch import useful_layers as ul layer = ul . layers . ChannelAttention2D ( in_channels = 5 , reduction = 2 ) block = ul . blocks . ScalingBlock ( layer )","title":"ScalingBlock"},{"location":"blocks/ScalingBlock/ScalingBlock/#scaling-block","text":"This block scales (i.e. multiplies) the original input with the activation map.","title":"Scaling Block"},{"location":"blocks/ScalingBlock/ScalingBlock/#class-scalingblock","text":"Simple scaling block. Parameter type Description input_layer useful_layers.layer Layer implementation to calculate activation map","title":"Class - ScalingBlock"},{"location":"blocks/ScalingBlock/ScalingBlock/#return-value","text":"The returned value is the product of the original input and the output of the layer.","title":"Return Value"},{"location":"blocks/ScalingBlock/ScalingBlock/#example","text":"A simple usage example without context: import torch import useful_layers as ul layer = ul . layers . ChannelAttention2D ( in_channels = 5 , reduction = 2 ) block = ul . blocks . ScalingBlock ( layer )","title":"Example"},{"location":"layers/Layers/","text":"useful_layers Layers module This module contains layers. Layers output their calculated results without applying them to the input. Layers do not use skip connections inside.","title":"Layers Introduction"},{"location":"layers/Layers/#useful_layers-layers-module","text":"This module contains layers. Layers output their calculated results without applying them to the input. Layers do not use skip connections inside.","title":"useful_layers Layers module"},{"location":"layers/channel_attention/","text":"Channel Attention Basic channel attention as presented in arxiv Class - ChannelAttention2D Simple ChannelAttention for 2D filters. Parameter type Description in_channels int Number of input channels reduction int, default=2 Degree of reduction Return Value The returned value is the channel attention map. This map is not applied to the original input in any way. Example A simple usage example without context: import torch import useful_layers as ul layer = ul . layers . ChannelAttention2D ( in_channels = 5 , reduction = 2 ) Class - ChannelAttention3D Simple ChannelAttention for 3D filters. Parameter type Description in_channels int Number of input channels reduction int, default=2 Degree of reduction Return Value The returned value is the channel attention map. This map is not applied to the original input in any way. Example A simple usage example without context: import torch import useful_layers as ul layer = ul . layers . ChannelAttention3D ( in_channels = 5 , reduction = 2 )","title":"Channel Attention"},{"location":"layers/channel_attention/#channel-attention","text":"Basic channel attention as presented in arxiv","title":"Channel Attention"},{"location":"layers/channel_attention/#class-channelattention2d","text":"Simple ChannelAttention for 2D filters. Parameter type Description in_channels int Number of input channels reduction int, default=2 Degree of reduction","title":"Class - ChannelAttention2D"},{"location":"layers/channel_attention/#return-value","text":"The returned value is the channel attention map. This map is not applied to the original input in any way.","title":"Return Value"},{"location":"layers/channel_attention/#example","text":"A simple usage example without context: import torch import useful_layers as ul layer = ul . layers . ChannelAttention2D ( in_channels = 5 , reduction = 2 )","title":"Example"},{"location":"layers/channel_attention/#class-channelattention3d","text":"Simple ChannelAttention for 3D filters. Parameter type Description in_channels int Number of input channels reduction int, default=2 Degree of reduction","title":"Class - ChannelAttention3D"},{"location":"layers/channel_attention/#return-value_1","text":"The returned value is the channel attention map. This map is not applied to the original input in any way.","title":"Return Value"},{"location":"layers/channel_attention/#example_1","text":"A simple usage example without context: import torch import useful_layers as ul layer = ul . layers . ChannelAttention3D ( in_channels = 5 , reduction = 2 )","title":"Example"},{"location":"layers/spatial_attention/","text":"Spatial Attention Basic spatial attention as presented in arxiv Class - SpatialAttention2D Simple SpatialAttention for 2D filters. Parameter type Description in_channels int Number of input channels kernel_size int, default=7 Filter size for convolution filter batch_norm bool, default=True If true batch normalization is applied Return Value The returned value is the spatial attention map. This map is not applied to the original input in any way. Example A simple usage example without context: import torch import useful_layers as ul layer = ul . layers . SpatialAttention2D ( in_channels = 5 , kernel_size = 2 ) Class - SpatialAttention3D Simple SpatialAttention for 3D filters. Parameter type Description in_channels int Number of input channels kernel_size int, default=7 Filter size for convolution filter batch_norm bool, default=True If true batch normalization is applied Return Value The returned value is the spatial attention map. This map is not applied to the original input in any way. Example A simple usage example without context: import torch import useful_layers as ul layer = ul . layers . SpatialAttention3D ( in_channels = 5 , kernel_size = 2 )","title":"Spatial Attention"},{"location":"layers/spatial_attention/#spatial-attention","text":"Basic spatial attention as presented in arxiv","title":"Spatial Attention"},{"location":"layers/spatial_attention/#class-spatialattention2d","text":"Simple SpatialAttention for 2D filters. Parameter type Description in_channels int Number of input channels kernel_size int, default=7 Filter size for convolution filter batch_norm bool, default=True If true batch normalization is applied","title":"Class - SpatialAttention2D"},{"location":"layers/spatial_attention/#return-value","text":"The returned value is the spatial attention map. This map is not applied to the original input in any way.","title":"Return Value"},{"location":"layers/spatial_attention/#example","text":"A simple usage example without context: import torch import useful_layers as ul layer = ul . layers . SpatialAttention2D ( in_channels = 5 , kernel_size = 2 )","title":"Example"},{"location":"layers/spatial_attention/#class-spatialattention3d","text":"Simple SpatialAttention for 3D filters. Parameter type Description in_channels int Number of input channels kernel_size int, default=7 Filter size for convolution filter batch_norm bool, default=True If true batch normalization is applied","title":"Class - SpatialAttention3D"},{"location":"layers/spatial_attention/#return-value_1","text":"The returned value is the spatial attention map. This map is not applied to the original input in any way.","title":"Return Value"},{"location":"layers/spatial_attention/#example_1","text":"A simple usage example without context: import torch import useful_layers as ul layer = ul . layers . SpatialAttention3D ( in_channels = 5 , kernel_size = 2 )","title":"Example"},{"location":"layers/squeeze_and_excitation/","text":"Squeeze and Excitation This module is inspired by the Squeeze and Excitation Normalization module: github or arxiv Class - SqueezeAndExcitation2D Simple SqueezeAndExcitation for 2D filters. Parameter type Description in_channels int Number of input channels reduction int, default=2 Degree of reduction Return Value The returned value is the squeeze and excitation map. This map is not applied to the original input in any way. Example A simple usage example without context: import torch import useful_layers as ul class demo ( torch . nn . Module ): def __init__ ( self , in_channels ): # ... self . layer = ul . layers . SqueezeAndExcitation2D ( in_channels = in_channels , reduction = 2 ) def forward ( self , x ): se_map = self . layer ( x ) # This map is not applied! return x * se_map # This is the default behaviour as described in the paper Class - SqueezeAndExcitation3D Simple SqueezeAndExcitation for 3D filters. Parameter type Description in_channels int Number of input channels reduction int, default=2 Degree of reduction Return Value The returned value is the Squeeze and Excitation map. This map is not applied to the original input in any way. Example A simple usage example without context: import torch import useful_layers as ul class demo ( torch . nn . Module ): def __init__ ( self , in_channels ): # ... self . layer = ul . layers . SqueezeAndExcitation3D ( in_channels = in_channels , reduction = 2 ) def forward ( self , x ): se_map = self . layer ( x ) # This map is not applied! return x * se_map # This is the default behaviour as described in the paper","title":"Squeeze and Excitation"},{"location":"layers/squeeze_and_excitation/#squeeze-and-excitation","text":"This module is inspired by the Squeeze and Excitation Normalization module: github or arxiv","title":"Squeeze and Excitation"},{"location":"layers/squeeze_and_excitation/#class-squeezeandexcitation2d","text":"Simple SqueezeAndExcitation for 2D filters. Parameter type Description in_channels int Number of input channels reduction int, default=2 Degree of reduction","title":"Class - SqueezeAndExcitation2D"},{"location":"layers/squeeze_and_excitation/#return-value","text":"The returned value is the squeeze and excitation map. This map is not applied to the original input in any way.","title":"Return Value"},{"location":"layers/squeeze_and_excitation/#example","text":"A simple usage example without context: import torch import useful_layers as ul class demo ( torch . nn . Module ): def __init__ ( self , in_channels ): # ... self . layer = ul . layers . SqueezeAndExcitation2D ( in_channels = in_channels , reduction = 2 ) def forward ( self , x ): se_map = self . layer ( x ) # This map is not applied! return x * se_map # This is the default behaviour as described in the paper","title":"Example"},{"location":"layers/squeeze_and_excitation/#class-squeezeandexcitation3d","text":"Simple SqueezeAndExcitation for 3D filters. Parameter type Description in_channels int Number of input channels reduction int, default=2 Degree of reduction","title":"Class - SqueezeAndExcitation3D"},{"location":"layers/squeeze_and_excitation/#return-value_1","text":"The returned value is the Squeeze and Excitation map. This map is not applied to the original input in any way.","title":"Return Value"},{"location":"layers/squeeze_and_excitation/#example_1","text":"A simple usage example without context: import torch import useful_layers as ul class demo ( torch . nn . Module ): def __init__ ( self , in_channels ): # ... self . layer = ul . layers . SqueezeAndExcitation3D ( in_channels = in_channels , reduction = 2 ) def forward ( self , x ): se_map = self . layer ( x ) # This map is not applied! return x * se_map # This is the default behaviour as described in the paper","title":"Example"}]}